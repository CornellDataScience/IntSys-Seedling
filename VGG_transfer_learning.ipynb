{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [helpful link](https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images under 5539\n",
      "Classes: \n",
      "['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n"
     ]
    }
   ],
   "source": [
    "#loading data 1\n",
    "\n",
    "data_dir = os.path.join('.', 'data')\n",
    "\n",
    "# VGG-16 Takes 224x224 images as input, so we resize all of them\n",
    "data_transform = transforms.Compose([transforms.Resize(256),transforms.CenterCrop(224),transforms.ToTensor()])\n",
    "\n",
    "image_dataset = datasets.ImageFolder(data_dir, transform=data_transform)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "        image_dataset, batch_size=32,\n",
    "        shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_size = len(image_dataset)\n",
    "\n",
    "print(\"Loaded images under {}\".format(dataset_size))\n",
    "    \n",
    "print(\"Classes: \")\n",
    "class_names = image_dataset.classes\n",
    "print(image_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "# calc balanced count\n",
    "class_counts = {}\n",
    "\n",
    "for i in range(len(image_dataset)):\n",
    "    label_index = image_dataset[i][1]\n",
    "    class_counts[label_index] = class_counts.get(label_index, 0) + 1\n",
    "    \n",
    "balanced_count = None\n",
    "balanced_class = None\n",
    "for class_ in class_counts:\n",
    "    if balanced_class is None or class_counts[class_] < class_counts[balanced_class]:\n",
    "        balanced_class = class_\n",
    "        balanced_count = class_counts[balanced_class]\n",
    "print(balanced_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data 3\n",
    "def indicesSplit_2sets(ds, balanced_size, percent_train=0.9, n_classes_pre = 8):\n",
    "    pretrain_indices = []\n",
    "    pretest_indices = []\n",
    "    \n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    counts = {}\n",
    "    \n",
    "    for i in range(len(ds)):\n",
    "        label_index = ds[i][1]\n",
    "        \n",
    "        counts[label_index] = counts.get(label_index, 0) + 1\n",
    "                \n",
    "        if counts[label_index] < balanced_size * percent_train:\n",
    "            if label_index < n_classes_pre:\n",
    "                pretrain_indices.append(i)\n",
    "            else:\n",
    "                train_indices.append(i)\n",
    "            \n",
    "        elif counts[label_index] < balanced_size:\n",
    "            if label_index < n_classes_pre:\n",
    "                pretest_indices.append(i)\n",
    "            else:\n",
    "                test_indices.append(i)\n",
    "        \n",
    "    return pretrain_indices, pretest_indices, train_indices, test_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data 4\n",
    "k = int(252*.9)\n",
    "\n",
    "pretrain_indices, pretest_indices, train_indices, test_indices = indicesSplit_2sets(image_dataset, balanced_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data 5\n",
    "\n",
    "pretrain_ds = Subset(image_dataset, pretrain_indices)\n",
    "pretest_ds = Subset(image_dataset, pretest_indices)\n",
    "train_ds = Subset(image_dataset, train_indices)\n",
    "test_ds = Subset(image_dataset, test_indices)\n",
    "\n",
    "\n",
    "pretrain_dataloader = DataLoader(\n",
    "        pretrain_ds, batch_size=32,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "pretest_dataloader = DataLoader(\n",
    "        pretest_ds, batch_size=32,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_ds, batch_size=32,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "test_dataloader = DataLoader(\n",
    "        test_ds, batch_size=32,\n",
    "        shuffle=True, num_workers=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "7\n",
      "29\n",
      "4\n",
      "tensor([3, 6, 4, 6, 7, 4, 7, 0, 3, 7, 5, 1, 1, 6, 2, 6, 7, 6, 5, 4, 7, 7, 1, 0,\n",
      "        0, 1, 2, 3, 7, 3, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "print(len(pretrain_dataloader))\n",
    "print(len(pretest_dataloader))\n",
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))\n",
    "\n",
    "c = 0\n",
    "for i in pretrain_dataloader:\n",
    "    if c == 0:\n",
    "        print(i[1])\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model, n_layers=30):\n",
    "    i = 0\n",
    "    for param in model.parameters():\n",
    "        if i < n_layers:\n",
    "            param.requires_grad = False\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layers(vgg16, n_layers=20)\n",
    "num_features = vgg16.classifier[6].in_features\n",
    "features = list(vgg16.classifier.children())[:-1] # Remove last layer\n",
    "features.extend([nn.Linear(num_features, 3*len(class_names))]) # Add our layer with 4 outputs\n",
    "features.extend([nn.Linear(3*len(class_names), len(class_names))]) # Add our layer with 4 outputs\n",
    "vgg16.classifier = nn.Sequential(*features) # Replace the model classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(vgg, num_images=6):\n",
    "    was_training = vgg.training\n",
    "    \n",
    "    # Set model for evaluation\n",
    "    vgg.train(False)\n",
    "    vgg.eval() \n",
    "    \n",
    "    images_so_far = 0\n",
    "\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        inputs, labels = data\n",
    "        size = inputs.size()[0]\n",
    "        \n",
    "        inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "        \n",
    "        outputs = vgg(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n",
    "        \n",
    "        print(\"Ground truth:\")\n",
    "        show_databatch(inputs.data.cpu(), labels.data.cpu())\n",
    "        print(\"Prediction:\")\n",
    "        show_databatch(inputs.data.cpu(), predicted_labels)\n",
    "        \n",
    "        del inputs, labels, outputs, preds, predicted_labels\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        images_so_far += size\n",
    "        if images_so_far >= num_images:\n",
    "            break\n",
    "        \n",
    "    vgg.train(mode=was_training) # Revert model back to original training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(vgg, criterion, test_dataloader):\n",
    "    since = time.time()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "    n = 0\n",
    "    \n",
    "    test_batches = len(test_dataloader)\n",
    "    print(\"Evaluating model\")\n",
    "    print('-' * 10)\n",
    "    \n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        print(\"\\rTest batch {}/{}\".format(i+1, test_batches), end='', flush=True)\n",
    "\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "        inputs, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "        outputs = vgg(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        n += len(preds)\n",
    "        loss_test += loss.data.item()\n",
    "        acc_test += torch.sum(preds == labels).item()\n",
    "\n",
    "        del inputs, labels, outputs, preds\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_loss = loss_test / n\n",
    "    avg_acc = acc_test / n\n",
    "    \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    vgg16.cuda() #.cuda() will move everything to the GPU side\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.0001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test before training\n",
      "Evaluating model\n",
      "----------\n",
      "Test batch 57/57\n",
      "Evaluation completed in 7m 33s\n",
      "Avg loss (test): 0.0786\n",
      "Avg acc (test): 0.0286\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"Test before training\")\n",
    "eval_model(vgg16, criterion, pretrain_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(vgg, criterion, optimizer, scheduler, train_dataloader, test_dataloader, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "#     avg_loss = 0\n",
    "#     avg_acc = 0\n",
    "#     avg_loss_val = 0\n",
    "#     avg_acc_val = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    train_batches = len(train_dataloader)\n",
    "    val_batches = len(test_dataloader)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        n_train = 0\n",
    "        n_val = 0\n",
    "        \n",
    "        vgg.train(True)\n",
    "        \n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            print(\"\\rTraining batch {}/{}\".format(i + 1, train_batches), end='', flush=True)\n",
    "                \n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            n_train += len(preds)\n",
    "            loss_train += loss.data.item()\n",
    "            acc_train += torch.sum(preds == labels.data).item()\n",
    "#             print(\"p\", preds)\n",
    "#             print(\"l\", labels.data)\n",
    "#             print(\"\\nn_correct\", torch.sum(preds == labels.data).item())\n",
    "#             print(\"n\", len(preds))\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_train = loss_train / n_train\n",
    "        avg_acc_train = acc_train / n_train\n",
    "        train_losses.append(avg_loss_train)\n",
    "        train_accs.append(avg_acc_train)\n",
    "\n",
    "\n",
    "        vgg.train(False)\n",
    "        #vgg.eval()\n",
    "            \n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            print(\"\\rValidation batch {}/{}\".format(i+1, val_batches), end='', flush=True)\n",
    "                \n",
    "            inputs, labels = data\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            n_val += len(preds)\n",
    "            loss_val += loss.data.item()\n",
    "            acc_val += torch.sum(preds == labels.data).item()\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_val = loss_val / n_val\n",
    "        avg_acc_val = acc_val / n_val\n",
    "        val_losses.append(avg_loss_val)\n",
    "        val_accs.append(avg_acc_val)\n",
    "\n",
    "\n",
    "        print()\n",
    "        print(\"Epoch {} result: \".format(epoch))\n",
    "        print(\"Avg loss (train): {:.4f}\".format(avg_loss_train))\n",
    "        print(\"Avg acc (train): {:.4f}\".format(avg_acc_train))\n",
    "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
    "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
    "        print('-' * 10)\n",
    "        print()\n",
    "        \n",
    "        if avg_acc_val > best_acc:\n",
    "            best_acc = avg_acc_val\n",
    "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "    return vgg, train_losses, train_accs, val_losses, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "Validation batch 7/7\n",
      "Epoch 0 result: \n",
      "Avg loss (train): 0.0761\n",
      "Avg acc (train): 0.1388\n",
      "Avg loss (val): 0.0809\n",
      "Avg acc (val): 0.2450\n",
      "----------\n",
      "\n",
      "\n",
      "Training completed in 9m 50s\n",
      "Best acc: 0.2450\n"
     ]
    }
   ],
   "source": [
    "pretrain_epoch = 30\n",
    "vgg16_pretrained, pretrain_losses, pretrain_accs, preval_losses, preval_accs \\\n",
    "    = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, pretrain_dataloader, pretest_dataloader, num_epochs=pretrain_epoch)\n",
    "\n",
    "\n",
    "torch.save(vgg16.state_dict(), 'VGG16_pretrained_subset_seedlings.pt')\n",
    "\n",
    "np.save(\"pretrain_losses\", np.array(pretrain_losses))\n",
    "np.save(\"pretrain_accs\", np.array(pretrain_accs))\n",
    "np.save(\"preval_losses\", np.array(preval_losses))\n",
    "np.save(\"preval_accs\", np.array(preval_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layers(vgg16_pretrained, n_layers=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test before training\n",
      "Evaluating model\n",
      "----------\n",
      "Test batch 4/4\n",
      "Evaluation completed in 0m 26s\n",
      "Avg loss (test): 0.1129\n",
      "Avg acc (test): 0.0000\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"Test before training\")\n",
    "eval_model(vgg16_pretrained, criterion, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "Validation batch 4/4\n",
      "Epoch 0 result: \n",
      "Avg loss (train): 0.0859\n",
      "Avg acc (train): 0.0220\n",
      "Avg loss (val): 0.0983\n",
      "Avg acc (val): 0.1900\n",
      "----------\n",
      "\n",
      "\n",
      "Training completed in 4m 32s\n",
      "Best acc: 0.1900\n"
     ]
    }
   ],
   "source": [
    "pretrain_epoch = 30\n",
    "vgg16_trained, train_losses, train_accs, val_losses, val_accs \\\n",
    "    = train_model(vgg16_pretrained, criterion, optimizer_ft, exp_lr_scheduler, train_dataloader, test_dataloader, num_epochs=pretrain_epoch)\n",
    "\n",
    "\n",
    "torch.save(vgg16.state_dict(), 'VGG16_transer_trained_subset_seedlings.pt')\n",
    "\n",
    "np.save(\"train_losses\", np.array(train_losses))\n",
    "np.save(\"train_accs\", np.array(train_accs))\n",
    "np.save(\"val_losses\", np.array(val_losses))\n",
    "np.save(\"val_accs\", np.array(val_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
