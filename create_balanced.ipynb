{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get started\n",
    "# IMPORTANT: Rename \"Shepard's Purse\" to \"Shepards Purse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import skimage\n",
    "\n",
    "import imageio\n",
    "\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seedling images should be located in a folder called data. The seedling categories:\n",
    "1. Black-grass\n",
    "2. Charlock\n",
    "3. Cleavers\n",
    "4. Common Chickweed\n",
    "5. Common wheat\n",
    "6. Fat Hen\n",
    "7. Loose Silky-bent\n",
    "8. Maize\n",
    "9. Scentless Mayweed\n",
    "10. Shepherd'd Purse\n",
    "11. Small-flowered Cranesbill\n",
    "12. Sugar beet \n",
    "<br>\n",
    "\n",
    "\n",
    "Within each seedling category, the images (pgn) are numbered 1,2,...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 138, 3)\n",
      "(145, 145, 3)\n",
      "(641, 641, 3)\n"
     ]
    }
   ],
   "source": [
    "#Each of the images has a different shape but three channels, rbg\n",
    "im1_path = os.path.join(\".\", \"data\", \"Black-grass\", \"1.png\")\n",
    "im2_path = os.path.join(\".\", \"data\", \"Black-grass\", \"7.png\")\n",
    "im3_path = os.path.join(\".\", \"data\", \"Black-grass\", \"200.png\")\n",
    "\n",
    "im1 = imageio.imread(im1_path)\n",
    "im2 = imageio.imread(im2_path)\n",
    "im3 = imageio.imread(im3_path)\n",
    "print(im1.shape)\n",
    "print(im2.shape)\n",
    "print(im3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shepherds Purse: 274\n",
      "Charlock: 452\n",
      "Cleavers: 335\n",
      "Fat Hen: 538\n",
      "Loose Silky-bent: 762\n",
      "Black-grass: 309\n",
      "Small-flowered Cranesbill: 576\n",
      "Maize: 257\n",
      "Common wheat: 253\n",
      "Scentless Mayweed: 607\n",
      "Sugar beet: 463\n",
      "Common Chickweed: 713\n",
      "---------\n",
      "Max Balanced: 253\n"
     ]
    }
   ],
   "source": [
    "# find max balanced\n",
    "\n",
    "data_path = os.path.join(\".\", \"data\")\n",
    "dir_list = os.listdir(data_path)\n",
    "\n",
    "max_balanced = 9999999999999\n",
    "\n",
    "for dir_ in dir_list:\n",
    "    n = 0\n",
    "    print(dir_, end=': ')\n",
    "    for name in os.listdir(os.path.join(data_path, dir_)):\n",
    "        if os.path.isfile(os.path.join(data_path, dir_, name)):\n",
    "            n = n + 1\n",
    "    print(n)\n",
    "    max_balanced = min(max_balanced, n)\n",
    "print(\"---------\")\n",
    "print(\"Max Balanced:\", max_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new balanced dataset with 253 imgs per class\n",
      "finished creating new balanced dataset\n",
      "3036\n",
      "3036\n"
     ]
    }
   ],
   "source": [
    "# create balanced dataset if doest exist already\n",
    "\n",
    "\n",
    "balanced_dir = os.path.join(\".\", 'balanced')\n",
    "\n",
    "if not os.path.exists(balanced_dir):\n",
    "    print(\"creating new balanced dataset with\", max_balanced, \"imgs per class\")\n",
    "    os.mkdir(balanced_dir)\n",
    "\n",
    "    for dir_ in dir_list:\n",
    "        n = 0\n",
    "        for name in os.listdir(os.path.join(data_path, dir_)):\n",
    "            src = os.path.join(data_path, dir_, name)\n",
    "            if os.path.isfile(src):\n",
    "                if(n < max_balanced):\n",
    "                    dst = os.path.join(balanced_dir, dir_ + \"_\" + str(n) + \".png\")\n",
    "                    copyfile(src, dst)\n",
    "                    n = n + 1\n",
    "    print(\"finished creating new balanced dataset\")\n",
    "else:\n",
    "    print(\"balanced dataset already exists\")\n",
    "print(len(os.listdir(balanced_dir)))\n",
    "print(12 * 253)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train a VGG16 model with weights pre-trained on ImageNet on all our categories.  We resize all images to 224X2254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATING TRAINING DATA\n",
    "\n",
    "def generateData(img_size):\n",
    "    \"\"\"\n",
    "    @param: img_size: size of image\n",
    "    \n",
    "    prints failed image paths\n",
    "    \n",
    "    @return: trainImg, trainTarget, validImg, validTarget\n",
    "    \"\"\"\n",
    "    allImg = []\n",
    "    allTarget = []\n",
    "\n",
    "    catNames = [\"Black-grass\", \"Charlock\", \"Cleavers\", \"Common Chickweed\", \"Common wheat\", \"Fat Hen\", \"Loose Silky-bent\", \"Maize\", \"Scentless Mayweed\", \"Shepherds Purse\", \"Small-flowered Cranesbill\", \"Sugar beet\"]\n",
    "\n",
    "    for cat in catNames:\n",
    "        tv = np.array([0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "        tv[catNames.index(cat)] = 1\n",
    "        assert np.max(tv) == 1 # make sure properly classfifiedd\n",
    "        for i in range (0,max_balanced):\n",
    "            imgPath = os.path.join(balanced_dir, cat + \"_\" + str(i) + \".png\")\n",
    "            if(os.path.isfile(imgPath)):\n",
    "                im_frame = cv2.imread(imgPath)\n",
    "                #resizing the image to img_size, img_size.  This is a basic solution to the issue to varying image size\n",
    "                res_im = cv2.resize(im_frame, (img_size, img_size), interpolation=cv2.INTER_LINEAR)\n",
    "                allImg.append(res_im)\n",
    "                allTarget.append(tv)\n",
    "            else:\n",
    "                print(imgPath)\n",
    "\n",
    "    allImg = np.array(allImg)\n",
    "    allTarget = np.array(allTarget)\n",
    "    \n",
    "    # train valid split\n",
    "    stratify = np.argmax(allTarget, axis = 1).reshape((allTarget.shape[0], 1))\n",
    "    return train_test_split(allImg, allTarget, test_size=0.1, random_state=13, stratify=allTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "trainX, validX, trainY, validY = generateData(img_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2732, 128, 128, 3)\n",
      "(2732, 12)\n",
      "(304, 128, 128, 3)\n",
      "(304, 12)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(validX.shape)\n",
    "print(validY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle load\n",
    "pickle_dir = os.path.join(\".\", 'balanced_pickled')\n",
    "\n",
    "if not os.path.exists(pickle_dir):\n",
    "    os.mkdir(pickle_dir)\n",
    "\n",
    "with open(os.path.join(\".\", \"balanced_pickled\", \"trainX_\" + str(img_size)), \"wb\") as f:\n",
    "    pickle.dump(trainX, f)\n",
    "with open(os.path.join(\".\", \"balanced_pickled\", \"trainY_\" + str(img_size)), \"wb\") as f:\n",
    "    pickle.dump(trainY, f)\n",
    "with open(os.path.join(\".\", \"balanced_pickled\", \"validX_\" + str(img_size)), \"wb\") as f:\n",
    "    pickle.dump(validX, f)\n",
    "with open(os.path.join(\".\", \"balanced_pickled\", \"validY_\" + str(img_size)), \"wb\") as f:\n",
    "    pickle.dump(validY, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle read\n",
    "with open(os.path.join(\".\", \"balanced_pickled\", \"trainX_\" + str(img_size)), \"rb\") as f:\n",
    "    assert pickle.load(f).shape == trainX.shape\n",
    "with open(os.path.join(\".\", \"balanced_pickled\", \"trainY_\" + str(img_size)), \"rb\") as f:\n",
    "    assert pickle.load(f).shape == trainY.shape\n",
    "with open(os.path.join(\".\", \"balanced_pickled\", \"validX_\" + str(img_size)), \"rb\") as f:\n",
    "    assert pickle.load(f).shape == validX.shape\n",
    "with open(os.path.join(\".\", \"balanced_pickled\", \"validY_\" + str(img_size)), \"rb\") as f:\n",
    "    assert pickle.load(f).shape == validY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
